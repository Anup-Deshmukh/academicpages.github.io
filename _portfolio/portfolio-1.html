---
title: "Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry Approach -- CentraleSupelec, France"
excerpt: "The emotion plays a key role in many applications like in healthcare domain to gather emotional behaviors. It is very crucial to determine “how it was said” other than “what it was said”. Therefore, in human- machine interaction applications, it is important that emotional states in human speech are fully perceived by Machine Learning model. Our ultimate goal at FAST lab was to model the stress from emotions. The abstract of this work is accepted in the International Conference on Speech Emotion Recognition and Affective Computing (ICSERAC) 2019. <br/><img src='/images/put3.png'>"
collection: portfolio
---
<body>
<p align="justify">The emotion plays a key role in many applications like in healthcare domain to gather emotional behaviors. It is very crucial to determine “how it was said” other than “what it was said”, Therefore, in human- machine interaction applications, it is important that emotional states in human speech are fully perceived by ML model well.</p>

<p align="justify">Our ultimate goal here at FAST lab is to model the stress from emotions. The amount of annotated data is limited and these annotations are highly subjective. Given this common issue in affective computation, the subjectivity lies in the fact that stress perceived by one person may be completely different from the other. Since we are not classifying the data into stress or not stress labels, we must find a way to map these emotions to stress. In short, identify where stress lies in the emotion space.</p>

<p align="justify">This brings us to many interesting theories in psychology like <a href="https://en.wikipedia.org/wiki/Emotion_classification">A&V</a>, <a href="https://en.wikipedia.org/wiki/PAD_emotional_state_model">PAD</a> and <a href="https://en.wikipedia.org/wiki/L%C3%B6vheim_cube_of_emotion">Lovheim cube</a>. What we are trying to acheive here at FAST lab is to see if our deep model: Emo-CNN follows these widely celebrated theories and whether it can model the emotional space described by them.</p>

<p align="justify"> This work is accepted in the <i>International Conference on Speech Emotion Recognition and Affective Computing <a href="https://waset.org/conference/2019/01/paris/ICSERAC">(ICSERAC) 2019 </a> </i> under the abstract submission category. We are currently working on our full paper and **results will be made available soon**</p>
<p align="justify"><a href="http://Anup-Deshmukh.github.io/files/EmoCNN.pdf"><font color="1ad1ff">Document</font></a></p>


</body>
