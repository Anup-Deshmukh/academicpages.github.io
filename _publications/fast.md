---
title: "Perception of emotions from Audio Signals"
collection: publications
permalink: /publication/fast
date: 2018-10-05

---

The emotion plays a key role in many applications like in healthcare domain to gather emotional behaviors. It is very crucial to determine “how it was said” other than “what it was said”,
Therefore, in human- machine interaction applications, it is important that emotional states in human speech are fully perceived by ML model well.

Our ultimate goal here at FAST lab was to to model the stress from emotions. The amount of annotated data is very limited and annotations are highly subjective. Given this common issue in affective computation, the subjectivity lies in the fact that stress perceived one person may be completely different from the other. Since we are not classifying the data into stress or not stress labels, we must find a way to map these emotions to stress. In short, identify where stress lies in emotion space. 

This brings us to the interesting theories in psychology, and what we are trying to acheive here at FAST lab is to see if our deep model: i-CNN follows these widely celebrated theories and whether it truly can model the emotional space described by them. 

**Our results will be available soon**

